{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class skinDetector(object):\n",
    "    #class constructor\n",
    "    def __init__(self, imageName,imagePath):\n",
    "        self.image = cv2.imread(imageName)\n",
    "        self.image_path=imagePath\n",
    "        if self.image is None:\n",
    "            print(\"IMAGE NOT FOUND\")\n",
    "            exit(1)                          \n",
    "        #self.image = cv2.resize(self.image,(600,600),cv2.INTER_AREA)\t\n",
    "        self.HSV_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2HSV)\n",
    "        self.YCbCr_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2YCR_CB)\n",
    "        self.binary_mask_image = self.HSV_image\n",
    "#================================================================================================================================\n",
    "    #function to process the image and segment the skin using the HSV and YCbCr colorspaces, followed by the Watershed algorithm\n",
    "    def find_skin(self):\n",
    "        self.__color_segmentation()\n",
    "        self.__region_based_segmentation()\n",
    "\n",
    "#================================================================================================================================\n",
    "    #Apply a threshold to an HSV and YCbCr images, the used values were based on current research papers along with some\n",
    "    # empirical tests and visual evaluation\n",
    "    def __color_segmentation(self):\n",
    "        lower_HSV_values = np.array([0, 40, 0], dtype = \"uint8\")\n",
    "        upper_HSV_values = np.array([25, 255, 255], dtype = \"uint8\")\n",
    "\n",
    "        lower_YCbCr_values = np.array((0, 138, 67), dtype = \"uint8\")\n",
    "        upper_YCbCr_values = np.array((255, 173, 133), dtype = \"uint8\")\n",
    "\n",
    "        #A binary mask is returned. White pixels (255) represent pixels that fall into the upper/lower.\n",
    "        mask_YCbCr = cv2.inRange(self.YCbCr_image, lower_YCbCr_values, upper_YCbCr_values)\n",
    "        mask_HSV = cv2.inRange(self.HSV_image, lower_HSV_values, upper_HSV_values) \n",
    "\n",
    "        self.binary_mask_image = cv2.add(mask_HSV,mask_YCbCr)\n",
    "\n",
    "#================================================================================================================================\n",
    "    #Function that applies Watershed and morphological operations on the thresholded image\n",
    "    def __region_based_segmentation(self):\n",
    "        #morphological operations\n",
    "        image_foreground = cv2.erode(self.binary_mask_image,None,iterations = 3)     \t#remove noise\n",
    "        dilated_binary_image = cv2.dilate(self.binary_mask_image,None,iterations = 3)   #The background region is reduced a little because of the dilate operation\n",
    "        ret,image_background = cv2.threshold(dilated_binary_image,1,128,cv2.THRESH_BINARY)  #set all background regions to 128\n",
    "\n",
    "        image_marker = cv2.add(image_foreground,image_background)   #add both foreground and backgroud, forming markers. The markers are \"seeds\" of the future image regions.\n",
    "        image_marker32 = np.int32(image_marker) #convert to 32SC1 format\n",
    "\n",
    "        cv2.watershed(self.image,image_marker32)\n",
    "        m = cv2.convertScaleAbs(image_marker32) #convert back to uint8 \n",
    "\n",
    "        #bitwise of the mask with the input image\n",
    "        ret,image_mask = cv2.threshold(m,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        output = cv2.bitwise_and(self.image,self.image,mask = image_mask)\n",
    "        cv2.imwrite(self.image_path,output)\n",
    "        #show the images\n",
    "#         self.show_image(self.image)\n",
    "#         self.show_image(image_mask)\n",
    "#         self.show_image(output)\n",
    "\n",
    "\n",
    "#================================================================================================================================\n",
    "    def show_image(self, image):\n",
    "        cv2.imshow(\"Image\",image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyWindow(\"Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_PATH = 'F:\\\\temp\\\\photos\\\\compressed_images\\\\completely_biased\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_PATH = 'F:\\\\temp\\\\photos\\\\mask_of_compressed_img\\\\completely_biased\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = f'{original_PATH}train\\\\'\n",
    "test_data_dir = f'{original_PATH}test\\\\'\n",
    "# validation_data_dir = f'{original_PATH}valid\\\\'\n",
    "\n",
    "mask_train_data_dir = f'{mask_PATH}train\\\\'\n",
    "mask_test_data_dir = f'{mask_PATH}test\\\\'\n",
    "# mask_validation_data_dir = f'{mask_PATH}valid\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=os.listdir(train_data_dir)\n",
    "for c in classes:\n",
    "    class_path=train_data_dir+c+'\\\\';\n",
    "    images=os.listdir(class_path)\n",
    "    for img in images:\n",
    "        img_name=img\n",
    "        detector = skinDetector(class_path+img_name, mask_train_data_dir+c+'\\\\'+img_name)\n",
    "        detector.find_skin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=os.listdir(test_data_dir)\n",
    "for c in classes:\n",
    "    class_path=test_data_dir+c+'\\\\';\n",
    "    images=os.listdir(class_path)\n",
    "    for img in images:\n",
    "        img_name=img\n",
    "        detector = skinDetector(class_path+img_name, mask_test_data_dir+c+'\\\\'+img_name)\n",
    "        detector.find_skin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=os.listdir(validation_data_dir)\n",
    "for c in classes:\n",
    "    class_path=validation_data_dir+c+'\\\\';\n",
    "    images=os.listdir(class_path)\n",
    "    for img in images:\n",
    "        img_name=img\n",
    "        detector = skinDetector(class_path+img_name, mask_validation_data_dir+c+'\\\\'+img_name)\n",
    "        detector.find_skin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert test photos to masked_photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_PATH = 'F:\\\\temp\\\\test_videos\\\\photos\\\\test2\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_PATH = 'F:\\\\temp\\\\test_videos\\\\photos\\\\test3_mask\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=os.listdir(original_PATH)\n",
    "for img in images:\n",
    "    img_name=img\n",
    "    detector = skinDetector(original_PATH+img_name, mask_PATH+'\\\\2'+img_name)\n",
    "    detector.find_skin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert custom photos mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class skinDetector(object):\n",
    "    #class constructor\n",
    "    def __init__(self, imageName,imagePath):\n",
    "        self.image = cv2.imread(imageName)\n",
    "        self.image_path=imagePath\n",
    "        if self.image is None:\n",
    "            print(\"IMAGE NOT FOUND\")\n",
    "            exit(1)                          \n",
    "        #self.image = cv2.resize(self.image,(600,600),cv2.INTER_AREA)\t\n",
    "        self.HSV_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2HSV)\n",
    "        self.YCbCr_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2YCR_CB)\n",
    "        self.binary_mask_image = self.HSV_image\n",
    "#================================================================================================================================\n",
    "    #function to process the image and segment the skin using the HSV and YCbCr colorspaces, followed by the Watershed algorithm\n",
    "    def find_skin(self):\n",
    "        self.__color_segmentation()\n",
    "        self.__region_based_segmentation()\n",
    "\n",
    "#================================================================================================================================\n",
    "    #Apply a threshold to an HSV and YCbCr images, the used values were based on current research papers along with some\n",
    "    # empirical tests and visual evaluation\n",
    "    def __color_segmentation(self):\n",
    "        lower_HSV_values = np.array([0, 40, 0], dtype = \"uint8\")\n",
    "        upper_HSV_values = np.array([25, 255, 255], dtype = \"uint8\")\n",
    "\n",
    "        lower_YCbCr_values = np.array((0, 138, 67), dtype = \"uint8\")\n",
    "        upper_YCbCr_values = np.array((255, 173, 133), dtype = \"uint8\")\n",
    "\n",
    "        #A binary mask is returned. White pixels (255) represent pixels that fall into the upper/lower.\n",
    "        mask_YCbCr = cv2.inRange(self.YCbCr_image, lower_YCbCr_values, upper_YCbCr_values)\n",
    "        mask_HSV = cv2.inRange(self.HSV_image, lower_HSV_values, upper_HSV_values) \n",
    "\n",
    "        self.binary_mask_image = cv2.add(mask_HSV,mask_YCbCr)\n",
    "\n",
    "#================================================================================================================================\n",
    "    #Function that applies Watershed and morphological operations on the thresholded image\n",
    "    def __region_based_segmentation(self):\n",
    "        #morphological operations\n",
    "        image_foreground = cv2.erode(self.binary_mask_image,None,iterations = 3)     \t#remove noise\n",
    "        dilated_binary_image = cv2.dilate(self.binary_mask_image,None,iterations = 3)   #The background region is reduced a little because of the dilate operation\n",
    "        ret,image_background = cv2.threshold(dilated_binary_image,1,128,cv2.THRESH_BINARY)  #set all background regions to 128\n",
    "\n",
    "        image_marker = cv2.add(image_foreground,image_background)   #add both foreground and backgroud, forming markers. The markers are \"seeds\" of the future image regions.\n",
    "        image_marker32 = np.int32(image_marker) #convert to 32SC1 format\n",
    "\n",
    "        cv2.watershed(self.image,image_marker32)\n",
    "        m = cv2.convertScaleAbs(image_marker32) #convert back to uint8 \n",
    "\n",
    "        #bitwise of the mask with the input image\n",
    "        ret,image_mask = cv2.threshold(m,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        output = cv2.bitwise_and(self.image,self.image,mask = image_mask)\n",
    "        cv2.imwrite(self.image_path,output)\n",
    "        #show the images\n",
    "#         self.show_image(self.image)\n",
    "#         self.show_image(image_mask)\n",
    "#         self.show_image(output)\n",
    "\n",
    "\n",
    "#================================================================================================================================\n",
    "    def show_image(self, image):\n",
    "        cv2.imshow(\"Image\",image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyWindow(\"Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_PATH = 'F:\\\\temp\\\\photos\\\\custom_sign\\\\food\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_PATH = 'F:\\\\temp\\\\photos\\\\custom_sign\\\\mask\\\\food\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=os.listdir(original_PATH)\n",
    "for img in images:\n",
    "    img_name=img\n",
    "    detector = skinDetector(original_PATH+img_name, mask_PATH+'\\\\'+img_name)\n",
    "    detector.find_skin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Open a simple image\n",
    "img=cv2.imread(\"F:\\\\Swastik\\\\study\\\\ml\\\\datasets\\\\speaking_silence_v2\\\\1\\\\train\\\\a\\\\3.png\")\n",
    "\n",
    "#converting from gbr to hsv color space\n",
    "img_HSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "#skin color range for hsv color space \n",
    "HSV_mask = cv2.inRange(img_HSV, (0, 15, 0), (17,170,255)) \n",
    "HSV_mask = cv2.morphologyEx(HSV_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "#converting from gbr to YCbCr color space\n",
    "img_YCrCb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "#skin color range for hsv color space \n",
    "YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255,180,135)) \n",
    "YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "#merge skin detection (YCbCr and hsv)\n",
    "global_mask=cv2.bitwise_and(YCrCb_mask,HSV_mask)\n",
    "global_mask=cv2.medianBlur(global_mask,3)\n",
    "global_mask = cv2.morphologyEx(global_mask, cv2.MORPH_OPEN, np.ones((4,4), np.uint8))\n",
    "\n",
    "\n",
    "HSV_result = cv2.bitwise_not(HSV_mask)\n",
    "YCrCb_result = cv2.bitwise_not(YCrCb_mask)\n",
    "global_result=cv2.bitwise_not(global_mask)\n",
    "\n",
    "\n",
    "#show results\n",
    "# cv2.imshow(\"1_HSV.jpg\",HSV_result)\n",
    "# cv2.imshow(\"2_YCbCr.jpg\",YCrCb_result)\n",
    "# cv2.imshow(\"3_global_result.jpg\",global_result)\n",
    "# cv2.imshow(\"Image.jpg\",img)\n",
    "cv2.imwrite(\"1_HSV.jpg\",HSV_result)\n",
    "cv2.imwrite(\"2_YCbCr.jpg\",YCrCb_result)\n",
    "cv2.imwrite(\"3_global_result.jpg\",global_result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.png',\n",
       " '1.png',\n",
       " '10.png',\n",
       " '100.png',\n",
       " '101.png',\n",
       " '102.png',\n",
       " '103.png',\n",
       " '104.png',\n",
       " '105.png',\n",
       " '106.png',\n",
       " '107.png',\n",
       " '108.png',\n",
       " '109.png',\n",
       " '11.png',\n",
       " '110.png',\n",
       " '111.png',\n",
       " '112.png',\n",
       " '113.png',\n",
       " '114.png',\n",
       " '115.png',\n",
       " '116.png',\n",
       " '117.png',\n",
       " '118.png',\n",
       " '119.png',\n",
       " '12.png',\n",
       " '120.png',\n",
       " '121.png',\n",
       " '122.png',\n",
       " '123.png',\n",
       " '124.png',\n",
       " '125.png',\n",
       " '126.png',\n",
       " '127.png',\n",
       " '128.png',\n",
       " '129.png',\n",
       " '13.png',\n",
       " '130.png',\n",
       " '131.png',\n",
       " '132.png',\n",
       " '133.png',\n",
       " '134.png',\n",
       " '135.png',\n",
       " '136.png',\n",
       " '137.png',\n",
       " '138.png',\n",
       " '139.png',\n",
       " '14.png',\n",
       " '140.png',\n",
       " '141.png',\n",
       " '142.png',\n",
       " '143.png',\n",
       " '144.png',\n",
       " '145.png',\n",
       " '146.png',\n",
       " '147.png',\n",
       " '148.png',\n",
       " '149.png',\n",
       " '15.png',\n",
       " '150.png',\n",
       " '151.png',\n",
       " '152.png',\n",
       " '153.png',\n",
       " '154.png',\n",
       " '155.png',\n",
       " '156.png',\n",
       " '157.png',\n",
       " '158.png',\n",
       " '159.png',\n",
       " '16.png',\n",
       " '160.png',\n",
       " '161.png',\n",
       " '162.png',\n",
       " '163.png',\n",
       " '164.png',\n",
       " '165.png',\n",
       " '166.png',\n",
       " '167.png',\n",
       " '168.png',\n",
       " '169.png',\n",
       " '17.png',\n",
       " '170.png',\n",
       " '171.png',\n",
       " '172.png',\n",
       " '173.png',\n",
       " '174.png',\n",
       " '175.png',\n",
       " '176.png',\n",
       " '177.png',\n",
       " '178.png',\n",
       " '179.png',\n",
       " '18.png',\n",
       " '180.png',\n",
       " '181.png',\n",
       " '182.png',\n",
       " '183.png',\n",
       " '184.png',\n",
       " '185.png',\n",
       " '186.png',\n",
       " '187.png',\n",
       " '188.png',\n",
       " '189.png',\n",
       " '19.png',\n",
       " '190.png',\n",
       " '191.png',\n",
       " '192.png',\n",
       " '193.png',\n",
       " '194.png',\n",
       " '195.png',\n",
       " '196.png',\n",
       " '197.png',\n",
       " '198.png',\n",
       " '199.png',\n",
       " '2.png',\n",
       " '20.png',\n",
       " '200.png',\n",
       " '201.png',\n",
       " '202.png',\n",
       " '203.png',\n",
       " '204.png',\n",
       " '205.png',\n",
       " '206.png',\n",
       " '207.png',\n",
       " '208.png',\n",
       " '209.png',\n",
       " '21.png',\n",
       " '210.png',\n",
       " '211.png',\n",
       " '212.png',\n",
       " '213.png',\n",
       " '214.png',\n",
       " '215.png',\n",
       " '216.png',\n",
       " '217.png',\n",
       " '218.png',\n",
       " '219.png',\n",
       " '22.png',\n",
       " '220.png',\n",
       " '221.png',\n",
       " '222.png',\n",
       " '223.png',\n",
       " '224.png',\n",
       " '225.png',\n",
       " '226.png',\n",
       " '227.png',\n",
       " '228.png',\n",
       " '229.png',\n",
       " '23.png',\n",
       " '230.png',\n",
       " '231.png',\n",
       " '232.png',\n",
       " '233.png',\n",
       " '234.png',\n",
       " '235.png',\n",
       " '236.png',\n",
       " '237.png',\n",
       " '238.png',\n",
       " '239.png',\n",
       " '24.png',\n",
       " '240.png',\n",
       " '241.png',\n",
       " '242.png',\n",
       " '243.png',\n",
       " '244.png',\n",
       " '245.png',\n",
       " '246.png',\n",
       " '247.png',\n",
       " '248.png',\n",
       " '249.png',\n",
       " '25.png',\n",
       " '250.png',\n",
       " '251.png',\n",
       " '252.png',\n",
       " '253.png',\n",
       " '254.png',\n",
       " '255.png',\n",
       " '256.png',\n",
       " '257.png',\n",
       " '258.png',\n",
       " '259.png',\n",
       " '26.png',\n",
       " '260.png',\n",
       " '261.png',\n",
       " '262.png',\n",
       " '263.png',\n",
       " '264.png',\n",
       " '265.png',\n",
       " '266.png',\n",
       " '267.png',\n",
       " '268.png',\n",
       " '269.png',\n",
       " '27.png',\n",
       " '270.png',\n",
       " '271.png',\n",
       " '272.png',\n",
       " '273.png',\n",
       " '274.png',\n",
       " '275.png',\n",
       " '276.png',\n",
       " '277.png',\n",
       " '278.png',\n",
       " '279.png',\n",
       " '28.png',\n",
       " '280.png',\n",
       " '281.png',\n",
       " '282.png',\n",
       " '283.png',\n",
       " '284.png',\n",
       " '285.png',\n",
       " '286.png',\n",
       " '287.png',\n",
       " '288.png',\n",
       " '289.png',\n",
       " '29.png',\n",
       " '290.png',\n",
       " '291.png',\n",
       " '292.png',\n",
       " '293.png',\n",
       " '294.png',\n",
       " '295.png',\n",
       " '296.png',\n",
       " '297.png',\n",
       " '298.png',\n",
       " '299.png',\n",
       " '3.png',\n",
       " '30.png',\n",
       " '300.png',\n",
       " '301.png',\n",
       " '302.png',\n",
       " '303.png',\n",
       " '304.png',\n",
       " '305.png',\n",
       " '306.png',\n",
       " '307.png',\n",
       " '308.png',\n",
       " '309.png',\n",
       " '31.png',\n",
       " '310.png',\n",
       " '311.png',\n",
       " '312.png',\n",
       " '313.png',\n",
       " '314.png',\n",
       " '315.png',\n",
       " '316.png',\n",
       " '317.png',\n",
       " '318.png',\n",
       " '319.png',\n",
       " '32.png',\n",
       " '320.png',\n",
       " '321.png',\n",
       " '322.png',\n",
       " '323.png',\n",
       " '324.png',\n",
       " '325.png',\n",
       " '326.png',\n",
       " '327.png',\n",
       " '328.png',\n",
       " '329.png',\n",
       " '33.png',\n",
       " '330.png',\n",
       " '331.png',\n",
       " '332.png',\n",
       " '333.png',\n",
       " '334.png',\n",
       " '335.png',\n",
       " '336.png',\n",
       " '337.png',\n",
       " '338.png',\n",
       " '339.png',\n",
       " '34.png',\n",
       " '340.png',\n",
       " '341.png',\n",
       " '342.png',\n",
       " '343.png',\n",
       " '344.png',\n",
       " '345.png',\n",
       " '346.png',\n",
       " '347.png',\n",
       " '348.png',\n",
       " '349.png',\n",
       " '35.png',\n",
       " '350.png',\n",
       " '351.png',\n",
       " '352.png',\n",
       " '353.png',\n",
       " '354.png',\n",
       " '355.png',\n",
       " '356.png',\n",
       " '357.png',\n",
       " '358.png',\n",
       " '359.png',\n",
       " '36.png',\n",
       " '360.png',\n",
       " '361.png',\n",
       " '362.png',\n",
       " '363.png',\n",
       " '364.png',\n",
       " '365.png',\n",
       " '366.png',\n",
       " '367.png',\n",
       " '368.png',\n",
       " '369.png',\n",
       " '37.png',\n",
       " '370.png',\n",
       " '371.png',\n",
       " '372.png',\n",
       " '373.png',\n",
       " '374.png',\n",
       " '375.png',\n",
       " '376.png',\n",
       " '377.png',\n",
       " '378.png',\n",
       " '379.png',\n",
       " '38.png',\n",
       " '380.png',\n",
       " '381.png',\n",
       " '382.png',\n",
       " '383.png',\n",
       " '384.png',\n",
       " '385.png',\n",
       " '386.png',\n",
       " '387.png',\n",
       " '388.png',\n",
       " '389.png',\n",
       " '39.png',\n",
       " '390.png',\n",
       " '391.png',\n",
       " '392.png',\n",
       " '393.png',\n",
       " '394.png',\n",
       " '395.png',\n",
       " '396.png',\n",
       " '397.png',\n",
       " '398.png',\n",
       " '399.png',\n",
       " '4.png',\n",
       " '40.png',\n",
       " '400.png',\n",
       " '401.png',\n",
       " '402.png',\n",
       " '403.png',\n",
       " '404.png',\n",
       " '405.png',\n",
       " '406.png',\n",
       " '407.png',\n",
       " '408.png',\n",
       " '409.png',\n",
       " '41.png',\n",
       " '410.png',\n",
       " '411.png',\n",
       " '412.png',\n",
       " '413.png',\n",
       " '414.png',\n",
       " '415.png',\n",
       " '416.png',\n",
       " '417.png',\n",
       " '418.png',\n",
       " '419.png',\n",
       " '42.png',\n",
       " '420.png',\n",
       " '421.png',\n",
       " '422.png',\n",
       " '423.png',\n",
       " '424.png',\n",
       " '425.png',\n",
       " '426.png',\n",
       " '427.png',\n",
       " '428.png',\n",
       " '429.png',\n",
       " '43.png',\n",
       " '430.png',\n",
       " '431.png',\n",
       " '432.png',\n",
       " '433.png',\n",
       " '434.png',\n",
       " '435.png',\n",
       " '436.png',\n",
       " '437.png',\n",
       " '438.png',\n",
       " '439.png',\n",
       " '44.png',\n",
       " '440.png',\n",
       " '441.png',\n",
       " '442.png',\n",
       " '443.png',\n",
       " '444.png',\n",
       " '445.png',\n",
       " '446.png',\n",
       " '447.png',\n",
       " '448.png',\n",
       " '449.png',\n",
       " '45.png',\n",
       " '450.png',\n",
       " '451.png',\n",
       " '452.png',\n",
       " '453.png',\n",
       " '454.png',\n",
       " '455.png',\n",
       " '456.png',\n",
       " '457.png',\n",
       " '458.png',\n",
       " '459.png',\n",
       " '46.png',\n",
       " '460.png',\n",
       " '461.png',\n",
       " '462.png',\n",
       " '463.png',\n",
       " '464.png',\n",
       " '465.png',\n",
       " '466.png',\n",
       " '467.png',\n",
       " '468.png',\n",
       " '469.png',\n",
       " '47.png',\n",
       " '470.png',\n",
       " '471.png',\n",
       " '472.png',\n",
       " '473.png',\n",
       " '474.png',\n",
       " '475.png',\n",
       " '476.png',\n",
       " '477.png',\n",
       " '478.png',\n",
       " '479.png',\n",
       " '48.png',\n",
       " '480.png',\n",
       " '481.png',\n",
       " '482.png',\n",
       " '483.png',\n",
       " '484.png',\n",
       " '485.png',\n",
       " '486.png',\n",
       " '487.png',\n",
       " '488.png',\n",
       " '489.png',\n",
       " '49.png',\n",
       " '490.png',\n",
       " '491.png',\n",
       " '492.png',\n",
       " '493.png',\n",
       " '494.png',\n",
       " '495.png',\n",
       " '496.png',\n",
       " '497.png',\n",
       " '498.png',\n",
       " '499.png',\n",
       " '5.png',\n",
       " '50.png',\n",
       " '500.png',\n",
       " '501.png',\n",
       " '502.png',\n",
       " '503.png',\n",
       " '504.png',\n",
       " '505.png',\n",
       " '506.png',\n",
       " '507.png',\n",
       " '508.png',\n",
       " '509.png',\n",
       " '51.png',\n",
       " '510.png',\n",
       " '511.png',\n",
       " '512.png',\n",
       " '513.png',\n",
       " '514.png',\n",
       " '515.png',\n",
       " '516.png',\n",
       " '517.png',\n",
       " '518.png',\n",
       " '519.png',\n",
       " '52.png',\n",
       " '520.png',\n",
       " '521.png',\n",
       " '522.png',\n",
       " '523.png',\n",
       " '524.png',\n",
       " '525.png',\n",
       " '526.png',\n",
       " '527.png',\n",
       " '528.png',\n",
       " '529.png',\n",
       " '53.png',\n",
       " '530.png',\n",
       " '531.png',\n",
       " '532.png',\n",
       " '533.png',\n",
       " '534.png',\n",
       " '535.png',\n",
       " '536.png',\n",
       " '537.png',\n",
       " '538.png',\n",
       " '539.png',\n",
       " '54.png',\n",
       " '540.png',\n",
       " '541.png',\n",
       " '542.png',\n",
       " '55.png',\n",
       " '56.png',\n",
       " '57.png',\n",
       " '58.png',\n",
       " '59.png',\n",
       " '6.png',\n",
       " '60.png',\n",
       " '61.png',\n",
       " '62.png',\n",
       " '63.png',\n",
       " '64.png',\n",
       " '65.png',\n",
       " '66.png',\n",
       " '67.png',\n",
       " '68.png',\n",
       " '69.png',\n",
       " '7.png',\n",
       " '70.png',\n",
       " '71.png',\n",
       " '72.png',\n",
       " '73.png',\n",
       " '74.png',\n",
       " '75.png',\n",
       " '76.png',\n",
       " '77.png',\n",
       " '78.png',\n",
       " '79.png',\n",
       " '8.png',\n",
       " '80.png',\n",
       " '81.png',\n",
       " '82.png',\n",
       " '83.png',\n",
       " '84.png',\n",
       " '85.png',\n",
       " '86.png',\n",
       " '87.png',\n",
       " '88.png',\n",
       " '89.png',\n",
       " '9.png',\n",
       " '90.png',\n",
       " '91.png',\n",
       " '92.png',\n",
       " '93.png',\n",
       " '94.png',\n",
       " '95.png',\n",
       " '96.png',\n",
       " '97.png',\n",
       " '98.png',\n",
       " '99.png']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"F:\\\\Swastik\\\\study\\\\ml\\\\datasets\\\\speaking_silence_v2\\\\1\\\\train\\\\a\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'F:\\\\temp\\\\photos\\\\original\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = f'{PATH}train\\\\'\n",
    "validation_data_dir = f'{PATH}test\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\temp\\\\photos\\\\original\\\\train\\\\'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class skinDetector(object):\n",
    "    #class constructor\n",
    "    def __init__(self, imageName,imagePath):\n",
    "        self.image = cv2.imread(imageName)\n",
    "        self.image_path=imagePath\n",
    "        if self.image is None:\n",
    "            print(\"IMAGE NOT FOUND\")\n",
    "            exit(1)                          \n",
    "        #self.image = cv2.resize(self.image,(600,600),cv2.INTER_AREA)\t\n",
    "        self.HSV_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2HSV)\n",
    "        self.YCbCr_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2YCR_CB)\n",
    "        self.binary_mask_image = self.HSV_image\n",
    "#================================================================================================================================\n",
    "    #function to process the image and segment the skin using the HSV and YCbCr colorspaces, followed by the Watershed algorithm\n",
    "    def find_skin(self):\n",
    "        self.__color_segmentation()\n",
    "        self.__region_based_segmentation()\n",
    "\n",
    "#================================================================================================================================\n",
    "    #Apply a threshold to an HSV and YCbCr images, the used values were based on current research papers along with some\n",
    "    # empirical tests and visual evaluation\n",
    "    def __color_segmentation(self):\n",
    "        lower_HSV_values = np.array([0, 40, 0], dtype = \"uint8\")\n",
    "        upper_HSV_values = np.array([25, 255, 255], dtype = \"uint8\")\n",
    "\n",
    "        lower_YCbCr_values = np.array((0, 138, 67), dtype = \"uint8\")\n",
    "        upper_YCbCr_values = np.array((255, 173, 133), dtype = \"uint8\")\n",
    "\n",
    "        #A binary mask is returned. White pixels (255) represent pixels that fall into the upper/lower.\n",
    "        mask_YCbCr = cv2.inRange(self.YCbCr_image, lower_YCbCr_values, upper_YCbCr_values)\n",
    "        mask_HSV = cv2.inRange(self.HSV_image, lower_HSV_values, upper_HSV_values) \n",
    "\n",
    "        self.binary_mask_image = cv2.add(mask_HSV,mask_YCbCr)\n",
    "\n",
    "#================================================================================================================================\n",
    "    #Function that applies Watershed and morphological operations on the thresholded image\n",
    "    def __region_based_segmentation(self):\n",
    "        #morphological operations\n",
    "        image_foreground = cv2.erode(self.binary_mask_image,None,iterations = 3)     \t#remove noise\n",
    "        dilated_binary_image = cv2.dilate(self.binary_mask_image,None,iterations = 3)   #The background region is reduced a little because of the dilate operation\n",
    "        ret,image_background = cv2.threshold(dilated_binary_image,1,128,cv2.THRESH_BINARY)  #set all background regions to 128\n",
    "\n",
    "        image_marker = cv2.add(image_foreground,image_background)   #add both foreground and backgroud, forming markers. The markers are \"seeds\" of the future image regions.\n",
    "        image_marker32 = np.int32(image_marker) #convert to 32SC1 format\n",
    "\n",
    "        cv2.watershed(self.image,image_marker32)\n",
    "        m = cv2.convertScaleAbs(image_marker32) #convert back to uint8 \n",
    "\n",
    "        #bitwise of the mask with the input image\n",
    "        ret,image_mask = cv2.threshold(m,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        output = cv2.bitwise_and(self.image,self.image,mask = image_mask)\n",
    "        cv2.imwrite(self.image_path,output)\n",
    "        #show the images\n",
    "#         self.show_image(self.image)\n",
    "#         self.show_image(image_mask)\n",
    "#         self.show_image(output)\n",
    "\n",
    "\n",
    "#================================================================================================================================\n",
    "    def show_image(self, image):\n",
    "        cv2.imshow(\"Image\",image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyWindow(\"Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = skinDetector(\"F:\\\\cropped.jpg\", \"F:\\\\output.jpg\")\n",
    "detector.find_skin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=os.listdir(train_data_dir)\n",
    "for c in classes:\n",
    "    class_path=train_data_dir+c+'\\\\';\n",
    "    images=os.listdir(class_path)\n",
    "    for img in images:\n",
    "        img_name=img\n",
    "        Skindet(class_path,c,img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\Swastik\\\\study\\\\ml\\\\datasets\\\\speaking_silence_v2\\\\1\\\\train\\\\c\\\\99.png'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\Swastik\\\\study\\\\ml\\\\datasets\\\\speaking_silence_v2\\\\1\\\\train\\\\c\\\\99.png'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_path+ img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
